{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework your task will be to modify `DecisionTreeClassifier` class from your practice in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (0.5 points) <br/>\n",
    "\n",
    "Download Telecom Data To Analyse The Churn Data Set `telecom_churn.csv`. Read it using `pandas.read_csv()` function. To open the function description use `Shift` + `Tab` . Show the first 5 rows of the dataset using `pandas.DataFrame.head()` function.\n",
    "\n",
    "[Dataset Information](https://www.kaggle.com/spscientist/telecom-data/download):\n",
    "\n",
    "Columns:\n",
    "* state (State letter code)/\n",
    "* account length (How long the client has been served by the company)\n",
    "* area code (Phone number prefix)\n",
    "* phone number\n",
    "* international plan (International roaming (connected / not connected))\n",
    "* voice mail plan (Voice mail (connected / not connected))\n",
    "* number vmail messages (Number of voice messages)\n",
    "* total day minutes (Total duration of conversations during the day)\n",
    "* total day calls (Total calls during the day)\n",
    "* total day charge (Total amount of payment for services during the day)\n",
    "* total eve minutes (Total duration of conversations in the evening)\n",
    "* total eve calls (Total number of calls in the evening)\n",
    "* total eve charge (Total amount of payment for services in the evening)\n",
    "* total night minutes (Total duration of conversations at night)\n",
    "* total night calls (Total number of calls at night)\n",
    "* total night charge (Total amount of payment for services at night)\n",
    "* total intl minutes (Total duration of international calls)\n",
    "* total intl calls (Total number of international call)\n",
    "* total intl charge (Total payment for international calls)\n",
    "* customer service calls (The number of calls to the service center)\n",
    "* churn\n",
    "\n",
    "Churn is target: True - client has left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account length  area code phone number international plan  \\\n",
       "0    KS             128        415     382-4657                 no   \n",
       "1    OH             107        415     371-7191                 no   \n",
       "2    NJ             137        415     358-1921                 no   \n",
       "3    OH              84        408     375-9999                yes   \n",
       "4    OK              75        415     330-6626                yes   \n",
       "\n",
       "  voice mail plan  number vmail messages  total day minutes  total day calls  \\\n",
       "0             yes                     25              265.1              110   \n",
       "1             yes                     26              161.6              123   \n",
       "2              no                      0              243.4              114   \n",
       "3              no                      0              299.4               71   \n",
       "4              no                      0              166.7              113   \n",
       "\n",
       "   total day charge  ...    total eve calls  total eve charge  \\\n",
       "0             45.07  ...                 99             16.78   \n",
       "1             27.47  ...                103             16.62   \n",
       "2             41.38  ...                110             10.30   \n",
       "3             50.90  ...                 88              5.26   \n",
       "4             28.34  ...                122             12.61   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   customer service calls  churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('telecom_churn.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which features are categorical? \n",
    "* Which features can be considered as object ID? Should we keep them? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer <br/>\n",
    "State, Area Code, International Plan, Voice Mail Plan are categorical features\n",
    "Phone number can be considered to be object ID. We shouldn't keep it, because it doesnt affect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['phone number']\n",
    "data = data.drop(cols_drop, axis=1)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (0.5 points) <br/>\n",
    "\n",
    "The target column for classification is `Churn`. However, it is categorical feature, so you need to encode this by `0` and `1` values (False = 0, True = 1). Implement this mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'churn'] = data.churn.replace({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrix `X` and vector of labels `y`. Split them into train and test samples using `sklearn.model_selection.train_test_split()` function from scikit-learn library. Also, set up random state in the function `random_state=42`.\n",
    "\n",
    "Expected output dataframes names: `df_X_train`, `df_X_test` и `y_train`, `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = \"churn\"\n",
    "X_columns = data.columns[data.columns != y_column]\n",
    "\n",
    "X = data[X_columns].values\n",
    "y = data[y_column].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_X_train, df_X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your result\n",
    "assert(round(df_X_test.size/X.size, 1)==0.2)\n",
    "assert(round(y_test.size/y.size, 1)==0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (2 points) categorical feature encoding\n",
    "\n",
    "Use (0, 1) for binary features. Replace values both for `df_X_train` and `df_X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_test = np.where(df_X_test == 'yes', 1, df_X_test)\n",
    "df_X_test = np.where(df_X_test == 'no', 0, df_X_test)\n",
    "\n",
    "df_X_train = np.where(df_X_train == 'yes', 1, df_X_train)\n",
    "df_X_train = np.where(df_X_train == 'no', 0, df_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement target encoding for other categorical features. For this task we propose you to implement the simpliest form of target encoding, which goes as following:\n",
    "\n",
    "Training:\n",
    "* Consider categorical feature $f$\n",
    "* For each category $c$ in this feature calculate mean value of target feature $y$: $v_c$\n",
    "\n",
    "Application:\n",
    "* Consider feature $f$\n",
    "* Replace each category $c$ with $v_c$\n",
    "* If $v_c$ is not calculated (possible new category) - replace $c$ with global target mean\n",
    "\n",
    "Create the next funсtions:\n",
    "* `learn_target_encoding `\n",
    "    * Input: train dataframe, target array, list of features names for encoding\n",
    "    * Output: nested dict with mapping from category to target encoded value for each categorical feature, global target mean value\n",
    "* `apply_target_encoding`\n",
    "    * Input: dataframe, encoding_dict\n",
    "    * Output: transformed dataframe in form of numpy array\n",
    "\n",
    "HINT for pandas:\n",
    "* `df.groupby(..)`\n",
    "* `df.column.to_dict(..)`\n",
    "* `df.column.replace(some_dict)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_target_encoding(df_input, y_input, features2encode):    \n",
    "    encoding_dict = {}\n",
    "    target_mean = y_input.mean()\n",
    "    df_input_copy = df_input.copy()\n",
    "    df_input_copy['y'] = y_input\n",
    "    for feature in features2encode:\n",
    "        encoding_dict[feature] = df_input_copy.groupby(by=feature)['y'].mean().to_dict()\n",
    "\n",
    "    return encoding_dict, target_mean\n",
    "\n",
    "def apply_target_encoding(df_input, encoding_dict, global_target_mean):\n",
    "    df_output = df_input.copy()\n",
    "    for key in df_output.to_dict():\n",
    "        index = 0\n",
    "        if key in encoding_dict:\n",
    "            for keys in df_output[key].values:\n",
    "                if keys in encoding_dict[key]:\n",
    "                    df_output[key][index] = encoding_dict[key][keys]\n",
    "                else:\n",
    "                    df_output[key][index] = global_target_mean\n",
    "                index += 1\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/denis/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "input_df = pd.read_csv(\"task4_train_only_for_check.csv\", sep=\"\\t\")\n",
    "features_list = ['cat2']\n",
    "\n",
    "X_dataframe = input_df[features_list]\n",
    "y_array = input_df['y']\n",
    "test_dataframe = pd.read_csv(\"task4_test_only_for_check.csv\", sep=\"\\t\")\n",
    "\n",
    "dictionary, glob_mean = learn_target_encoding(X_dataframe, y_array, features_list)\n",
    "output_matrix = apply_target_encoding(test_dataframe, dictionary, glob_mean)\n",
    "\n",
    "assert(np.array_equal(output_matrix, np.array([[0, 0, 0, 1, 1, 0], [3, 3, 5, 4, 2, 3.076923076923077]]).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalCols = ['state', 'area code', 'international plan', 'voice mail plan']\n",
    "\n",
    "df_X_train = pd.DataFrame(df_X_train, columns = X_columns) \n",
    "df_X_test = pd.DataFrame(df_X_test, columns = X_columns) \n",
    "y_array = y_train \n",
    "dictionary, glob_mean = learn_target_encoding(df_X_train, y_array, categoricalCols) \n",
    "df_X_train = apply_target_encoding(df_X_train, dictionary, glob_mean) \n",
    "df_X_test = apply_target_encoding(df_X_test, dictionary, glob_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (1 point) <br/>\n",
    "\n",
    "Now let's look at this data. For each input feature plot historgrams, as it was done in you practice in class. How do you think, what features are the most informative? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "color kwarg must have one color per dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-43ae46333aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Plot histograms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3135\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3136\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3137\u001b[0;31m                       stacked=stacked, normed=normed, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3138\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   6611\u001b[0m             \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6613\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"color kwarg must have one color per dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6615\u001b[0m         \u001b[0;31m# If bins are not specified either explicitly or via range,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: color kwarg must have one color per dataset"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x7200 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define size of the figure\n",
    "\n",
    "plt.figure(figsize=(30, 100))\n",
    "\n",
    "# For each column ...\n",
    "for i_col in range(len(df_X_train.columns)):\n",
    "    \n",
    "    # Create subplot for each column\n",
    "    plt.subplot(23, 3, i_col+1)\n",
    "    \n",
    "    # Get column and label values\n",
    "    x_col = df_X_train[X_columns[i_col]].values\n",
    "    y_col = y_train\n",
    "    # Plot histograms\n",
    "    bins = np.linspace(0, x_col.max(), 21)\n",
    "    plt.hist(x_col[y_col == 0], bins=bins, color=['r','b'], alpha=0.5, label='0')\n",
    "    plt.hist(x_col[y_col == 1], bins=bins, color='b', alpha=0.5, label='1')\n",
    "    \n",
    "    # Labels and legend\n",
    "    plt.xlabel(df_X_train.columns[i_col])\n",
    "    plt.ylabel('Counts')\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (1 point) <br/>\n",
    "\n",
    "Fit `DecisionTreeClassifier` from you practice in class with this sample. Find the best parameters. What is `accuracy` of the classification on the test sample?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Class for a decision tree node.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        \n",
    "        self.threshold = None\n",
    "        self.column = None\n",
    "        self.info_gain = None\n",
    "        self.nt = 0\n",
    "        \n",
    "        self.depth = None\n",
    "        self.probas = None\n",
    "        \n",
    "        self.is_terminal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    \n",
    "    def __init__(self, max_depth=3, min_samples_leaf=1, min_samples_split=2, impurity='gini'):\n",
    "        \n",
    "        # Make hyperparameters visible inside the class\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.impurity = impurity\n",
    "        \n",
    "        self.qwe = {}\n",
    "        \n",
    "        # Object for the decision tree\n",
    "        self.Tree = None\n",
    "        \n",
    "        # Helping objects\n",
    "        self.classes = []\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        \n",
    "\n",
    "        params = {'max_depth': self.max_depth,\n",
    "                  'min_samples_leaf': self.min_samples_leaf,\n",
    "                  'min_samples_split': self.min_samples_split,\n",
    "                  'impurity': self.impurity}\n",
    "\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "\n",
    "\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "        return self\n",
    "\n",
    "        \n",
    "    \n",
    "    def node_probabilities(self, y):\n",
    "       \n",
    "        \n",
    "        # To store probas\n",
    "        probas = []\n",
    "        \n",
    "        # For each class in data ...\n",
    "        for one_class in self.classes:\n",
    "            \n",
    "            # Estimate probability of the class\n",
    "            class_proba = 1. * (y == one_class).sum() / len(y)\n",
    "            # class_proba = 0.8 (example)\n",
    "            \n",
    "            # Store the probability\n",
    "            probas.append(class_proba)\n",
    "            \n",
    "        return probas\n",
    "    \n",
    "    \n",
    "    def gini_calculation(self, probas):\n",
    "       \n",
    "        \n",
    "        gini = 1\n",
    "        for p in probas:\n",
    "            gini -= p**2\n",
    "        \n",
    "        return gini\n",
    "    \n",
    "    \n",
    "    def impurity_calculation(self, y):\n",
    "        \n",
    "                \n",
    "        # Estimate probabilities for each class\n",
    "        probas = self.node_probabilities(y)\n",
    "        # probas = [0.90, 0.10] (example)\n",
    "        \n",
    "        # Calculate impurity of the data\n",
    "        if self.impurity == 'gini':\n",
    "            impurity = self.gini_calculation(probas)\n",
    "            # impurity = 0.6 (example)\n",
    "        \n",
    "        return impurity\n",
    "        \n",
    "    \n",
    "    def best_split(self, X, y):\n",
    "        \n",
    "        \n",
    "        # To store best split parameters\n",
    "        best_split_column = None\n",
    "        best_threshold = None\n",
    "        best_information_gain = -999\n",
    "        \n",
    "        # Data impurity before the split\n",
    "        impurity = self.impurity_calculation(y)\n",
    "        # impurity = 0.8 (example)\n",
    "        \n",
    "        # For each column in X ...\n",
    "        for split_column in range(X.shape[1]):\n",
    "            \n",
    "            # Select values of the column\n",
    "            x_col = X[:, split_column]\n",
    "            # x_col = [2.6, 1.3, 0.5, ...] (example)\n",
    "            \n",
    "            # For each value in the column ...\n",
    "            for i_x in range(0, len(x_col)):\n",
    "                \n",
    "                # Take the value as a threshold for a split\n",
    "                threshold = x_col[i_x]\n",
    "                # threshold = 1.3 (example)\n",
    "                \n",
    "                # Make the split into right and left childs\n",
    "                y_right = y[x_col > threshold]\n",
    "                y_left = y[x_col <= threshold]\n",
    "                # y_left = [0, 1, 1, 0, 1] (example)\n",
    "                \n",
    "                if len(y_right) == 0 or len(y_left) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate impurity for each child\n",
    "                impurity_left = self.impurity_calculation(y_left)\n",
    "                impurity_right = self.impurity_calculation(y_right)\n",
    "                # impurity_right = 0.6 (example)\n",
    "                \n",
    "                # Calculate information gain of the split\n",
    "                information_gain = impurity\n",
    "                information_gain -= impurity_left * len(y_left) / len(y)\n",
    "                information_gain -= impurity_right * len(y_right) / len(y)\n",
    "                # information_gain = 0.2 (example)\n",
    "                \n",
    "                # Is this information_gain the best?\n",
    "                if information_gain > best_information_gain:\n",
    "                    best_split_column = split_column\n",
    "                    best_threshold = threshold\n",
    "                    best_information_gain = information_gain\n",
    "                    \n",
    "        # If no split available\n",
    "        if best_information_gain == -999:\n",
    "            return None, None, None, None, None, None\n",
    "        \n",
    "        # Take the best split parameters and make this split\n",
    "        x_col = X[:, best_split_column]\n",
    "        X_left = X[x_col <= best_threshold, :]\n",
    "        y_left = y[x_col <= best_threshold]\n",
    "        X_right = X[x_col > best_threshold, :]\n",
    "        y_right = y[x_col > best_threshold]\n",
    "        \n",
    "        return best_split_column, best_threshold, X_left, y_left, X_right, y_right, best_information_gain\n",
    "                    \n",
    "                \n",
    "    \n",
    "    def decision_tree(self, node, X, y):\n",
    "       \n",
    "        # Check termination conditions\n",
    "        if node.depth >= self.max_depth:      # max_depth check\n",
    "            node.is_terminal = True\n",
    "            node.nt = len(y)\n",
    "            return\n",
    "        if len(X) < self.min_samples_split:   # min_samples_split check\n",
    "            node.is_terminal = True\n",
    "            node.nt = len(y)\n",
    "            return\n",
    "        if len(np.unique(y)) == 1:\n",
    "            node.is_terminal = True\n",
    "            node.nt = len(y)\n",
    "            return\n",
    "        \n",
    "        # Make best split\n",
    "        split_column, threshold, X_left, y_left, X_right, y_right, information_gain = self.best_split(X, y) # Make a split\n",
    "        # split_column = 2 (exmaple) column index of the split\n",
    "        # threshold = 2.74 (example) split_column > threshold\n",
    "        \n",
    "        # Check additional termination conditions\n",
    "        if split_column is None:\n",
    "            node.is_terminal = True\n",
    "            node.nt = len(y)\n",
    "            return\n",
    "        if len(X_left) < self.min_samples_leaf or len(X_right) < self.min_samples_leaf:  # min_samples_leaf check\n",
    "            node.is_terminal = True\n",
    "            node.nt = len(y)\n",
    "            return\n",
    "        \n",
    "        \n",
    "        # Add split parameters into the current node\n",
    "        node.column = split_column\n",
    "        node.threshold = threshold\n",
    "        node.info_gain = information_gain\n",
    "        node.nt += len(y_right) + len(y_left)\n",
    "            \n",
    "        # Create a left child of the current node\n",
    "        node.left = Node()\n",
    "        node.left.depth = node.depth + 1\n",
    "        node.left.probas = self.node_probabilities(y_left)\n",
    "        \n",
    "        # Create a right child of the current node\n",
    "        node.right = Node()\n",
    "        node.right.depth = node.depth + 1\n",
    "        node.right.probas = self.node_probabilities(y_right)\n",
    "        \n",
    "        # Make splits for the left and right nodes\n",
    "        self.decision_tree(node.right, X_right, y_right)\n",
    "        self.decision_tree(node.left, X_left, y_left)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "       \n",
    "        # Get unique class labels\n",
    "        self.classes = np.unique(y)\n",
    "        # self.classes = [0, 1] (example)\n",
    "        \n",
    "        # Create a root node of a decision tree\n",
    "        self.Tree = Node()                             # Create an empty node\n",
    "        self.Tree.depth = 1                            # the node depth\n",
    "        self.Tree.probas = self.node_probabilities(y)  # init class probabilities\n",
    "        \n",
    "        # Build the decision tree\n",
    "        self.decision_tree(self.Tree, X, y)\n",
    "        \n",
    "    def one_prediction(self, node, x):\n",
    "        \n",
    "        # Termination condition\n",
    "        if node.is_terminal == True:     # If it is a leaf (terminal node, no childs)\n",
    "            return node.probas                           # Return probas of the terminal node\n",
    "            # node.probas = [0.9, 0.1] (example)\n",
    "        \n",
    "        # Run to the current node's childs\n",
    "        # Check split condition. If yes, go to the right child\n",
    "        \n",
    "        \n",
    "        if x[node.column] > node.threshold:\n",
    "            # Right child\n",
    "            probas = self.one_prediction(node.right, x)\n",
    "            # probas = [0.9, 0.1] (example)\n",
    "        else: \n",
    "            # Left child\n",
    "            probas = self.one_prediction(node.left, x)\n",
    "            # probas = [0.9, 0.1] (example)\n",
    "            \n",
    "        return probas\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        \n",
    "        # Create an empty list for predicted probabilities\n",
    "        y_predicted_proba = []\n",
    "        \n",
    "        # For each object in X make a prediction\n",
    "        for one_x in X:\n",
    "            \n",
    "            # Make the prediction for one object \n",
    "            one_proba = self.one_prediction(self.Tree, one_x)\n",
    "            # one_proba = [0.9, 0.1] (example)\n",
    "            \n",
    "            # Store the predictions\n",
    "            y_predicted_proba.append(one_proba)\n",
    "        \n",
    "        return np.array(y_predicted_proba)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        # Predict probabilities\n",
    "        y_predicted_proba = self.predict_proba(X)\n",
    "        # y_predicted_proba = [[0.90, 0.10], \n",
    "        #                      [0.23, 0.77], \n",
    "        #                       ...]  (example)\n",
    "        \n",
    "        # Find class labels with the highest probability\n",
    "        y_predicted = y_predicted_proba.argmax(axis=1)\n",
    "        # y_predicted = [0, 1] (example)\n",
    "        \n",
    "        return y_predicted\n",
    "\n",
    "    \n",
    "    def recur(self, node):\n",
    "        if node.is_terminal:\n",
    "            return node.nt\n",
    "        q1 = self.recur(node.left)\n",
    "        q2 = self.recur(node.right)\n",
    "        \n",
    "        col = node.column\n",
    "        \n",
    "        if col in self.qwe:\n",
    "            self.qwe[col] += (q1*node.info_gain + q2*node.info_gain)\n",
    "        else:\n",
    "            self.qwe[col] = (q1*node.info_gain + q2*node.info_gain)\n",
    "            \n",
    "        return node.nt\n",
    "    \n",
    "    \n",
    "    def DDDD(self):\n",
    "        return self.Tree\n",
    "    \n",
    "    def CopyTree(self, node):\n",
    "        import copy\n",
    "        newRoot = copy.copy(node)\n",
    "        return newRoot\n",
    "    \n",
    "    def RemoveSubTree(self, node):\n",
    "        if node.right.nt > node.left.nt:\n",
    "            node = node.right\n",
    "        else:\n",
    "            node = node.left\n",
    "            \n",
    "    def goBut(self, node):\n",
    "        if node.is_terminal:\n",
    "            return False\n",
    "        if node.right.is_terminal and node.left.is_terminal:\n",
    "            self.RemoveSubTree(node)\n",
    "            return True\n",
    "        else:\n",
    "            if goBut(node.left) == False:\n",
    "                return goBut(node.right)\n",
    "            else:\n",
    "                return True\n",
    "        \n",
    "    def Prun(self):\n",
    "        newRoot = self.CopyTree(self.Tree)\n",
    "        isChange = self.goBut(newRoot)\n",
    "        if isChange:\n",
    "            ## CAlcularte\n",
    "        else:\n",
    "            print(\"Nothing to change\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-3355ea08f7d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_X_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-10dfbb2409e0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# Build the decision tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-10dfbb2409e0>\u001b[0m in \u001b[0;36mdecision_tree\u001b[0;34m(self, node, X, y)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# Make best split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0msplit_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformation_gain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Make a split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;31m# split_column = 2 (exmaple) column index of the split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# threshold = 2.74 (example) split_column > threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-10dfbb2409e0>\u001b[0m in \u001b[0;36mbest_split\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;31m# Calculate impurity for each child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mimpurity_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpurity_calculation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mimpurity_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpurity_calculation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0;31m# impurity_right = 0.6 (example)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-10dfbb2409e0>\u001b[0m in \u001b[0;36mimpurity_calculation\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Estimate probabilities for each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;31m# probas = [0.90, 0.10] (example)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-10dfbb2409e0>\u001b[0m in \u001b[0;36mnode_probabilities\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Estimate probability of the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mclass_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mone_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;31m# class_proba = 0.8 (example)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=30, \n",
    "                             min_samples_leaf=1, \n",
    "                             min_samples_split=2, \n",
    "                             impurity='gini')\n",
    "\n",
    "parameters = {'max_depth':[1, 3, 5, 7, 9], \n",
    "              'min_samples_leaf':[1, 5, 10],\n",
    "              'min_samples_split':[1,3,5,7,10]}\n",
    "\n",
    "gs = GridSearchCV(clf,                 # Classifier object to optimize\n",
    "                  parameters,          # Grid of the hyperparameters\n",
    "                  scoring='accuracy',  # Claasification quality metric to optimize\n",
    "                  cv=3)                # Number of folds in KFolds cross-validation (CV)\n",
    "\n",
    "\n",
    "gs.fit(df_X_train.values, y_train)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (3 points) <br/>\n",
    "\n",
    "Implement feature importance estimation in `DecisionTreeClassifier`. Importance of a feature $f$ is defined as follows:\n",
    "\n",
    "* Let $T(f)$ be the set of all nodes, relying on feature $f$ when making split.\n",
    "* Efficiency of split at node $t$: $\\Delta I(t)=I(t)-\\sum_{c\\in childen(t)}\\frac{n_{c}}{n_{t}}I(c)$,  where $n_t$, $n_c$ is number of samples in nodes t, c\n",
    "* Feature importance of $f$: $\\sum_{t\\in T(f)}n_{t}\\Delta I(t)$, where $n_t$ is number of samples in node t\n",
    "\n",
    "Calculate importance of input features in your dataset. What features are the most important (informative) for the classification?\n",
    "\n",
    "To do this you have to update your decision_tree learning procedure:\n",
    "* Return best_information_gain from best_split\n",
    "* Save best_information_gain in node\n",
    "* Traverse tree recursively and caclulate feature importance for every feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Output: array 'features_order' from highest to lowest importance (first 5)\n",
    "clf = DecisionTreeClassifier(max_depth=7, min_samples_leaf=1, min_samples_split=2, impurity='gini')\n",
    "clf.fit(df_X_train.values, y_train)\n",
    "clf.recur(clf.Tree)\n",
    "features_or = clf.qwe\n",
    "features_or = {k: v for k, v in sorted(features_or.items(), key=lambda item: item[1], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['total day minutes', 'customer service calls', 'total eve minutes',\n",
      "       'total intl minutes', 'international plan'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "features_order = df_X_train.columns[list(features_or.keys())[:5]]\n",
    "print(features_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-5f7b4de2203e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total day charge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'customer service calls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'international plan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total intl calls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total eve charge'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(len(features_order)==5)\n",
    "assert(np.array_equal(features_order, np.array(['total day charge', 'customer service calls', 'international plan', 'total intl calls', 'total eve charge'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2666\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "q1 = clf.CopyTree(clf.Tree)\n",
    "q1.nt = 10\n",
    "print(clf.DDDD().nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (2 points) <br/>\n",
    "\n",
    "Implement Reduced Error Pruning in you `DecisionTreeClassifier`. \n",
    "\n",
    "Fit the classifier similar to **Task 6** setting up `max_depth=20`. \n",
    "\n",
    "Prune this decision tree using train data. \n",
    "\n",
    "Create a plot \"Accuracy (y-axis) vs Numbers of vertices (x-axis)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "449.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
